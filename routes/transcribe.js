import express from 'express';
import multer from 'multer';
import fs from 'fs';
import path from 'path';
import ffmpeg from 'fluent-ffmpeg';
import { transcribeAudio } from '../utils/whisperClient.js';

const router = express.Router();
const upload = multer({ dest: 'uploads/' });

router.post('/', upload.single('file'), async (req, res) => {
  try {
    if (!req.file || !req.file.path) {
      console.warn("‚ö†Ô∏è No file uploaded.");
      return res.status(400).json({ error: 'No file uploaded.' });
    }

    const filePath = req.file.path;
    const originalName = req.file.originalname;

    console.log("üßæ Uploaded file:", {
      path: filePath,
      originalName,
      mime: req.file.mimetype,
      size: req.file.size
    });

    // Step 1: Detect duration using ffprobe
    ffmpeg.ffprobe(filePath, async (err, metadata) => {
      if (err) {
        console.error("‚ùå ffprobe error:", err);
        return res.status(500).json({ error: "Could not determine file duration." });
      }

      const durationSeconds = metadata.format.duration || 0;
      const durationMinutes = Math.ceil(durationSeconds / 60);

      console.log(`‚è±Ô∏è Duration: ${durationMinutes} min ‚Üí should deduct ${durationMinutes * 2} tokens`);

      // Step 2: Transcribe
      console.log("üéß Starting transcription...");
      const transcript = await transcribeAudio(filePath, originalName);

      fs.unlink(filePath, () => {}); // Clean up uploaded file
      console.log("‚úÖ Transcription complete.");

      // Step 3: Return transcript + duration for frontend deduction
      res.json({ text: transcript, durationMinutes });
    });

  } catch (err) {
    console.error("‚ùå Transcription route error:", err);
    res.status(500).json({ error: 'Failed to transcribe audio.' });
  }
});

export default router;
